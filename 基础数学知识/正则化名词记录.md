**经验风险**和**结构风险**是评估模型性能的两个重要概念，分别反映模型在训练数据上的表现和泛化能力。

### 1. 经验风险（Empirical Risk）
- **定义**：模型在训练数据上的平均损失，衡量模型对已知数据的拟合程度。
- **公式**：
  \[
  R_{\text{emp}}(f) = \frac{1}{n} \sum_{i=1}^{n} L(y_i, f(x_i))
  \]
  其中，\( L \) 是损失函数，\( y_i \) 是真实标签，\( f(x_i) \) 是模型预测，\( n \) 是样本数量。
- **意义**：反映模型在训练数据上的误差，值越小表示拟合越好。
- **局限性**：仅关注训练数据，可能导致过拟合。

### 2. 结构风险（Structural Risk）
- **定义**：经验风险与模型复杂度惩罚项的结合，旨在平衡拟合能力和泛化能力。
- **公式**：
  \[
  R_{\text{struct}}(f) = R_{\text{emp}}(f) + \lambda \cdot \Phi(f)
  \]
  其中，\( \lambda \) 是正则化系数，\( \Phi(f) \) 是模型复杂度惩罚项。
- **意义**：通过惩罚复杂模型，防止过拟合，提升泛化能力。
- **常用方法**：
  - **L1正则化（Lasso）**：倾向于产生稀疏模型。
  - **L2正则化（Ridge）**：限制模型参数的大小。

### 3. 经验风险与结构风险的区别
- **经验风险**：仅关注训练数据上的表现，可能导致过拟合。
- **结构风险**：在经验风险基础上加入复杂度惩罚，平衡拟合与泛化。

### 4. 应用
- **经验风险最小化（ERM）**：直接最小化经验风险，适用于数据充足且简单模型。
- **结构风险最小化（SRM）**：最小化结构风险，适用于数据有限或复杂模型，防止过拟合。

### 总结
- **经验风险**衡量模型在训练数据上的误差。
- **结构风险**在经验风险基础上加入复杂度惩罚，防止过拟合，提升泛化能力。
- **选择**：数据充足且简单时可用ERM，数据有限或模型复杂时建议使用SRM。

**L1范数**和**L2范数**是衡量向量大小的常用方法，广泛应用于机器学习中的正则化、特征选择等任务。

### 1. L1范数（L1 Norm）
- **定义**：向量各元素绝对值之和。
- **公式**：
  \[
  \| \mathbf{x} \|_1 = \sum_{i=1}^{n} |x_i|
  \]
  其中，\( \mathbf{x} = (x_1, x_2, \ldots, x_n) \) 是一个 \( n \) 维向量。
- **特点**：
  - **稀疏性**：倾向于使部分元素为零，适用于特征选择。
  - **鲁棒性**：对异常值不敏感。
- **应用**：
  - **L1正则化（Lasso回归）**：通过L1范数惩罚模型参数，产生稀疏解。
  - **特征选择**：自动选择重要特征，去除冗余。

### 2. L2范数（L2 Norm）
- **定义**：向量各元素平方和的平方根，即欧几里得距离。
- **公式**：
  \[
  \| \mathbf{x} \|_2 = \sqrt{\sum_{i=1}^{n} x_i^2}
  \]
- **特点**：
  - **平滑性**：倾向于使所有元素较小，但不为零。
  - **对异常值敏感**：受大值元素影响较大。
- **应用**：
  - **L2正则化（Ridge回归）**：通过L2范数惩罚模型参数，防止过拟合。
  - **距离度量**：用于计算向量间的欧几里得距离。

### 3. L1范数与L2范数的对比
| 特性          | L1范数                          | L2范数                          |
|---------------|--------------------------------|--------------------------------|
| **定义**      | 绝对值之和                     | 平方和的平方根                 |
| **稀疏性**    | 产生稀疏解                     | 不产生稀疏解                   |
| **鲁棒性**    | 对异常值不敏感                 | 对异常值敏感                   |
| **应用**      | Lasso回归，特征选择            | Ridge回归，距离度量            |

### 4. 正则化中的应用
- **L1正则化（Lasso回归）**：
  \[
  \text{损失函数} + \lambda \| \mathbf{w} \|_1
  \]
  其中，\( \mathbf{w} \) 是模型参数，\( \lambda \) 是正则化系数。
- **L2正则化（Ridge回归）**：
  \[
  \text{损失函数} + \lambda \| \mathbf{w} \|_2^2
  \]

### 总结
- **L1范数**：绝对值之和，倾向于稀疏解，适用于特征选择。
- **L2范数**：平方和的平方根，倾向于小参数值，适用于防止过拟合。
- **选择**：根据具体任务需求选择合适的范数。