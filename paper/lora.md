# LoRA （Low-rank Adaptation of LLMs）

本质： 用更少的训练参数来近似LLM全参微调所得到的增量参数

### LoRA和 训练目标是解耦的，和语言模型和图形图像处理无关

每次进行FFT时，学习一个$\delta,\delta$的参数量特别大
**核心思想**：将参数增量$\delta$用一个参数量更小的$\gamma$表示，$|\gamma| << |\delta|$

矩阵分解，一个d x d的矩阵（d > 512）可以用两个矩阵 A.size = [d x r], B.size = [r x d]来表示

在训练时冻结预训练模型的权重，用参数量更小的矩阵进行低秩近似训练。

## LoRA参数初始化

首先要求两个矩阵A，B的矩阵乘法结果 AB = 0，所以A，B两个至少有一个为全0

但如果二者都为0，A，B就训不动，因为这个时候处在鞍点，两个权重的梯度也全为0，B的梯度依赖A，A的梯度依赖B

